# Rundeck AI â€“ Painel de Falhas Ã— Alto Tempo (RBM)

Painel estÃ¡tico para **leitura operacional** de riscos em jobs (Rundeck): combina **falha** e **alto tempo** de execuÃ§Ã£o, priorizando hotspots e amostras com maior probabilidade de problema.  
**Fonte de dados:** `./app/ai_analysis.json` servido no **mesmo domÃ­nio** do site (sameâ€‘origin).

---

## ğŸ“ Arquitetura (visÃ£o de ponta a ponta)

```mermaid
flowchart LR
  subgraph User["ğŸ§‘â€ğŸ’» OperaÃ§Ã£o / Diretoria"]
    B[Browser<br/>index.html + app.js]
  end

  subgraph Hosting["CDN/Hosting estÃ¡tico"]
    H[/Site estÃ¡tico<br/>(HTML, JS, CSS)/]
    J[(/app/ai_analysis.json)]
  end

  subgraph Pipeline["Pipeline de Dados (CI/CD ou Scheduler)"]
    R[Rundeck / CI]
    E[etl.py<br/>â†’ limpeza/joins]
    F[features.py<br/>â†’ engenharia de atributos]
    M[rbm_train.py<br/>â†’ treino RBM / score]
    G[build_ai_json.py<br/>â†’ gera ai_analysis.json]
  end

  B -- GET /index.html, /app.js --> H
  B -- GET /app/ai_analysis.json --> J

  R --> E --> F --> M --> G --> J

  classDef box fill:#0b1220,stroke:#243041,color:#e2e8f0,stroke-width:1px;
  class B,H,J,R,E,F,M,G box;
```

**Fluxo:**  
1) O **Pipeline** (Rundeck/CI) processa dados histÃ³ricos, treina/aplica RBM e **gera `ai_analysis.json`** dentro de `/app/`.  
2) O **Hosting estÃ¡tico** publica o site (index.html, app.js) e o JSON no **mesmo domÃ­nio**.  
3) O **Browser** faz `fetch('./app/ai_analysis.json')` e renderiza KPIs, grÃ¡ficos e tabelas.

> Sem dependÃªncia de S3 pÃºblico. O JSON Ã© empacotado e servido pelo prÃ³prio hosting do site.

---

## ğŸ§  RBM (Restricted Boltzmann Machine) â€“ como usamos

**Objetivo:** dar um **score de â€œestranhezaâ€** para execuÃ§Ãµes de jobs combinando sinais (duraÃ§Ã£o, horÃ¡rio, tipo de falha, sazonalidade, etc.). Itens com **erro de reconstruÃ§Ã£o** maior que um limiar sugerem **anomalia**.

### 1) IntuiÃ§Ã£o
Uma RBM modela distribuiÃ§Ã£o de probabilidade de um vetor de entrada \( \mathbf{v} \) (**visÃ­vel**) via unidades **ocultas** \( \mathbf{h} \). A RBM aprende padrÃµes â€œnormaisâ€. Quando recebe uma entrada que **nÃ£o se parece** com o que aprendeu, o **erro de reconstruÃ§Ã£o** aumenta.

### 2) EquaÃ§Ãµes essenciais
- Energia do par \((\mathbf{v}, \mathbf{h})\):  
  \[ E(\mathbf{v},\mathbf{h}) = -\mathbf{b}^\top \mathbf{v} - \mathbf{c}^\top \mathbf{h} - \mathbf{v}^\top W \mathbf{h} \]
- AtivaÃ§Ãµes condicionais (Bernoulli):
  \[ p(h_j=1|\mathbf{v}) = \sigma(c_j + W_{:,j}^\top \mathbf{v}), \quad
     p(v_i=1|\mathbf{h}) = \sigma(b_i + W_{i,:}\mathbf{h}) \]
- **Erro de reconstruÃ§Ã£o** (mÃ©trica prÃ¡tica):  
  \[ \text{RE}(\mathbf{v}) = \|\mathbf{v} - \hat{\mathbf{v}}\|_2^2 \]  
  onde \( \hat{\mathbf{v}} \) Ã© a reconstruÃ§Ã£o apÃ³s uma etapa Gibbs.

### 3) Pipeline de anÃ¡lise (alto nÃ­vel)
1. **ETL (`etl.py`)**: agrega execuÃ§Ãµes (job, projeto, status, duraÃ§Ã£o_s, data/hora, etc.).  
2. **Features (`features.py`)**: normaliza/oneâ€‘hot e cria atributos Ãºteis (hora do dia, dia da semana, p95 histÃ³rico, desvio vs. mÃ©dia, sazonalidade).  
3. **Treino/Score (`rbm_train.py`)**: usa `sklearn.neural_network.BernoulliRBM` para treinar em histÃ³rico **saudÃ¡vel** (ou com rÃ³tulos filtrados). Gera **erro de reconstruÃ§Ã£o** por execuÃ§Ã£o.  
4. **Risco combinado (`build_ai_json.py`)**: consolida mÃ©tricas por job (mÃ©dia, p95, contagem de eventos cruzados falhaÃ—alto tempo) e produz `ai_analysis.json`.

### 4) Como o painel decide â€œhotspotsâ€
- **Eventos cruzados**: contagem de execuÃ§Ãµes com **falha** e **duraÃ§Ã£o acima do p95** (mesmo job).  
- **Risco p95 por job**: para cada job, calcula p95 de duraÃ§Ã£o e exibe junto Ã  mÃ©dia.  
- **Top amostras**: ordena execuÃ§Ãµes com maior score (erro de reconstruÃ§Ã£o) e evidencia as piores.

> VocÃª pode calibrar limiares (ex.: percentil 95 do **RE**) ou usar mÃ©todos como **IQR** para â€œoutlier scoreâ€.

---

## ğŸ“„ Esquema do `ai_analysis.json` (mÃ­nimo)

```json
{
  "meta": { "modelo": "BernoulliRBM", "periodo": "Ãºltimo trimestre", "gerado_em": "YYYY-MM-DDThh:mm:ssZ" },
  "resumo": {
    "registros": 2500,
    "falhas": 87,
    "alto_tempo": 42,
    "eventos_cruzados": 19,
    "taxa_cruzada": 0.34,
    "phi": 0.21,
    "lift": 1.8
  },
  "hotspots": [
    { "projeto": "core", "job": "daily_settlement", "eventos": 12, "risco_medio": 0.73, "risco_p95": 0.92, "duracao_media_s": 410 }
  ],
  "risco_p95_por_job": [
    { "job": "daily_settlement", "p95": 732, "duracao_media": 410 }
  ],
  "top_amostras": [
    { "projeto": "core", "job": "daily_settlement", "exec_id": "abc", "inicio": "2025-09-17T10:00:00Z", "status": "FAILED", "duracao_s": 930, "risco": 0.92 }
  ]
}
```

**ObservaÃ§Ãµes**
- Evite `NaN`, `Infinity` e comentÃ¡rios no JSON.  
- NÃºmeros com vÃ­rgula (`"0,9"`) sÃ£o tolerados no front, mas prefira ponto decimal.

---

## ğŸ› ï¸ Scripts (exemplos de referÃªncia)

### `etl.py` (pseudoâ€‘cÃ³digo)
```python
import pandas as pd

df = pd.read_csv("execucoes.csv")  # colunas: projeto, job, inicio, status, duracao_s, ...
# limpeza/normalizaÃ§Ã£o
df = df.dropna(subset=["job", "duracao_s"]).copy()
df["duracao_s"] = df["duracao_s"].astype(float)
df.to_parquet("stage/execucoes.parquet", index=False)
```

### `features.py`
```python
import pandas as pd
import numpy as np

df = pd.read_parquet("stage/execucoes.parquet")
df["inicio"] = pd.to_datetime(df["inicio"])
df["hora"] = df["inicio"].dt.hour
df["dow"]  = df["inicio"].dt.dayofweek
# p95 histÃ³rico por job
p95 = df.groupby("job")["duracao_s"].quantile(0.95).rename("p95_job")
feat = df.join(p95, on="job")
feat["ratio_p95"] = feat["duracao_s"] / np.maximum(feat["p95_job"], 1.0)
# one-hot simples
feat = pd.get_dummies(feat, columns=["status","dow","hora"], drop_first=True)
feat.to_parquet("stage/features.parquet", index=False)
```

### `rbm_train.py` (score por execuÃ§Ã£o)
```python
import pandas as pd
import numpy as np
from sklearn.neural_network import BernoulliRBM
from sklearn.preprocessing import MinMaxScaler

X = pd.read_parquet("stage/features.parquet").select_dtypes(include=[np.number]).fillna(0.0).values
sc = MinMaxScaler()
Xn = sc.fit_transform(X)

rbm = BernoulliRBM(n_components=64, learning_rate=0.05, batch_size=64, n_iter=30, verbose=True)
rbm.fit(Xn)

# reconstruÃ§Ã£o
H = rbm.transform(Xn)              # p(h=1|v)
V_hat = rbm.gibbs(H)               # reconstruÃ§Ã£o aproximada
re = ((Xn - V_hat) ** 2).sum(axis=1)  # erro L2

pd.DataFrame({"re": re}).to_parquet("stage/score.parquet", index=False)
```

### `build_ai_json.py` (consolidaÃ§Ã£o e JSON final)
```python
import json, numpy as np, pandas as pd

execs = pd.read_parquet("stage/execucoes.parquet")
score = pd.read_parquet("stage/score.parquet")
df = execs.join(score)

# eventos cruzados: falha & acima do p95 do prÃ³prio job
p95 = df.groupby("job")["duracao_s"].quantile(0.95).rename("p95_job")
df = df.join(p95, on="job")
df["alto_tempo"] = df["duracao_s"] > df["p95_job"]
df["falhou"] = df["status"].ne("SUCCESS")

eventos_cruz = df.loc[df["alto_tempo"] & df["falhou"]]

hot = (eventos_cruz.groupby(["projeto","job"])
       .agg(eventos=("job","count"),
            risco_medio=("re","mean"),
            risco_p95=("re",lambda s: float(np.percentile(s,95))),
            duracao_media_s=("duracao_s","mean"))
       .reset_index()
       .sort_values("eventos", ascending=False)
       .head(20))

risco_job = (df.groupby("job")
             .agg(p95=("duracao_s", lambda s: float(np.percentile(s,95))),
                  duracao_media=("duracao_s","mean"))
             .reset_index())

top = (df.sort_values("re", ascending=False)
       .head(50)[["projeto","job","exec_id","inicio","status","duracao_s"]]
       .assign(risco=lambda x: x.index.map(lambda i: float(df.loc[x.index[i],"re"]))))

resumo = {
  "registros": int(len(df)),
  "falhas": int(df["falhou"].sum()),
  "alto_tempo": int(df["alto_tempo"].sum()),
  "eventos_cruzados": int(len(eventos_cruz)),
  "taxa_cruzada": round(len(eventos_cruz)/max(1,len(df)), 3),
  "phi": round(float(df["falhou"].mean() * df["alto_tempo"].mean()), 3),  # proxy simples
  "lift": round(float((df["falhou"] & df["alto_tempo"]).mean() / max(1e-6, df["falhou"].mean())), 2)
}

out = {
  "meta": { "modelo": "BernoulliRBM", "periodo": "Ãºltimo trimestre" },
  "resumo": resumo,
  "hotspots": hot.to_dict(orient="records"),
  "risco_p95_por_job": risco_job.to_dict(orient="records"),
  "top_amostras": top.to_dict(orient="records")
}

with open("app/ai_analysis.json","w",encoding="utf-8") as f:
  json.dump(out, f, ensure_ascii=False, indent=2)
```

---

## ğŸš€ Front-end (sameâ€‘origin)

- **Busca**: `new URL('./app/ai_analysis.json?ts=' + Date.now(), document.baseURI)`  
- **Cache**: `cache: 'no-store'` + header `Cache-Control: no-cache` no hosting.  
- **ResiliÃªncia**: sanitizaÃ§Ã£o de nÃºmeros (â€œ0,9â€), tolerÃ¢ncia a chaves `snake_case`/`camelCase`.

**Rewrites/Redirects (ordem importa)**  
1. `source: /app/<*>  â†’  target: /app/<*>  (200 Rewrite)`  
2. `source: /<*>      â†’  target: /index.html  (200 Rewrite)`

**Custom headers**  
- `Source: /app/*.json`  
  `Content-Type: application/json`  
  `Cache-Control: no-cache`

---

## ğŸ”§ InstalaÃ§Ã£o & Build (sem bundler)

**Estrutura mÃ­nima**:
```
/app
  â”œâ”€ index.html
  â”œâ”€ app.js
  â””â”€ app/
     â””â”€ ai_analysis.json
```

**Build simples** (copia /app â†’ artifact):
```yaml
version: 1
frontend:
  phases:
    build:
      commands:
        - rm -rf webout && mkdir -p webout
        - cp -r app/* webout/
  artifacts:
    baseDirectory: webout
    files:
      - '**/*'
```

Se usar Node/bundler dentro de `/app`, adicione `npm ci && npm run build` e publique `dist/` ou `build/` conforme seu toolchain.

---

## ğŸ©º Troubleshooting

- **â€œErro ao carregar dadosâ€** no painel â†’ abra DevTools/Network e verifique `/app/ai_analysis.json`:
  - **Preview mostra HTML** â†’ a regra `/app/<*>` estÃ¡ **abaixo** da SPA; ajuste a ordem.
  - **404** â†’ o JSON nÃ£o foi incluÃ­do no artifact (copie `app/ai_analysis.json` no build).
  - **Content-Type** incorreto â†’ configure `application/json`.
  - **JSON invÃ¡lido** (`NaN`, vÃ­rgulas finais, comentÃ¡rios) â†’ valide antes de publicar.

- **GrÃ¡fico trava** â†’ sanitizaÃ§Ã£o jÃ¡ inclusa no `app.js`; ainda assim, normalize nÃºmeros no JSON.

---

## âœ… Boas prÃ¡ticas

- Treinar RBM em perÃ­odo considerado **saudÃ¡vel** (ou com filtros).  
- Atualizar o JSON pelo menos **1Ã—/dia** (ou por janela operacional).  
- Versionar `ai_analysis.json` para auditoria (timestamp em `meta.gerado_em`).  
- Acompanhar **tendÃªncias**: queda/subida sistemÃ¡tica do p95 e do erro mÃ©dio por job.

---

## ğŸ“œ LicenÃ§a

Uso interno. Ajuste conforme sua polÃ­tica.
